{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# If you are using CUDA, set the seed for all GPUs\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################Inter the Parameters###############################################################\n",
    "\n",
    "#Hypervector Size\n",
    "hv_d = 10000\n",
    "\n",
    "# Number of Epochs\n",
    "n_epochs = 10\n",
    "\n",
    "#Epsilon Values\n",
    "eps = 10\n",
    "\n",
    "#Number of Rounds\n",
    "round_needed = 10\n",
    "\n",
    "#Number of Clients\n",
    "n_clients = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import time\n",
    "import random\n",
    "from scipy import stats\n",
    "import torchhd\n",
    "import torch\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm_notebook\n",
    "from tabulate import tabulate\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.misc\n",
    "from PIL import Image\n",
    "import skimage\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import normalize\n",
    "import pickle\n",
    "from sklearn.utils import resample\n",
    "import torchhd.embeddings as embeddings\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "data_file = 'data_hole_diameter_10.pkl'\n",
    "\n",
    "# Load data and labels from the specified file\n",
    "with open(data_file, 'rb') as f:\n",
    "    all_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11318\n"
     ]
    }
   ],
   "source": [
    "batch_data = all_dataset['1']['traindata']\n",
    "batch_labels = all_dataset['1']['trainlabels']\n",
    "nClasses = len(np.unique(batch_labels))\n",
    "nFeatures = batch_data.shape[1]\n",
    "len_train = len(batch_data)\n",
    "print(len_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(len_train//round_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = embeddings.Density(nFeatures, hv_d).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_HD(data,labels,embed,nClasses,hv_d):\n",
    "    class_hvs = torch.zeros((nClasses,hv_d), dtype=torch.float64).cuda()\n",
    "    for i_sub in range(len(data)):\n",
    "        class_hvs[labels[i_sub]] += torch.sign(embed(data[i_sub]))\n",
    "        \n",
    "    return class_hvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Update_HD(chv,data,labels,embed,n_epochs):\n",
    "        \n",
    "    for i_epoch in range(n_epochs): \n",
    "        stop = 1\n",
    "        len_train_sh = list(range(len(data)))\n",
    "        random.shuffle(len_train_sh)\n",
    "        for i_sub in len_train_sh:\n",
    "            encd_sample =torch.sign(torch.tensor(embed(data[i_sub]), dtype=torch.float64).cuda())\n",
    "            guess = torch.matmul(chv,encd_sample).argmax()\n",
    "            if guess!= labels[i_sub]:\n",
    "                chv[labels[i_sub]] += encd_sample\n",
    "                chv[guess] -= encd_sample\n",
    "                stop = 0\n",
    "\n",
    "\n",
    "        if stop == 1:\n",
    "            break \n",
    "            \n",
    "    return chv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Infer(chv,testdata,testlabels,embed):\n",
    "    \n",
    "    count = 0\n",
    "    for i_sub in list(range(len(testdata))):\n",
    "        encd_sample = torch.sign(torch.tensor(embed(testdata[i_sub]), dtype=torch.float64).cuda())\n",
    "        guess = torch.matmul(chv,encd_sample).argmax()\n",
    "        if guess== testlabels[i_sub]:\n",
    "            count += 1\n",
    "    test_acc = count/len(testlabels)\n",
    "\n",
    "    return  test_acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Noise_first_round(chv,eps,hv_d,batch_size):\n",
    "    \n",
    "    std_noise = np.sqrt(2*hv_d*np.log(1.25*batch_size))/eps\n",
    "    \n",
    "    class_noisy = torch.zeros(chv.shape, dtype=torch.float64).cuda()\n",
    "    for i_class in range(len(chv)):\n",
    "        class_noisy[i_class] = chv[i_class] + torch.normal(mean=0, std = std_noise, size=(hv_d,)).cuda()\n",
    "\n",
    "    return class_noisy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pert_Noise(chv,eps,hv_d,batch_size,rnd,n_clients):\n",
    "    \n",
    "    coef_l = (2*hv_d)/(eps**2)\n",
    "    val_l = np.log((1.25*(rnd-1)*n_clients*batch_size)+(1.25*batch_size))\n",
    "    real_l = coef_l * val_l\n",
    "    \n",
    "    \n",
    "    coef_r = (2*hv_d)/(n_clients*(eps**2))\n",
    "    val_r = np.log((1.25*(rnd-2)*n_clients*batch_size)+(1.25*batch_size))\n",
    "    real_r = coef_r * val_r\n",
    "    \n",
    "    sigma_noise = real_l - real_r\n",
    "    \n",
    "    class_noisy = torch.zeros(chv.shape, dtype=torch.float64).cuda()\n",
    "    for i_class in range(len(chv)):\n",
    "        class_noisy[i_class] = chv[i_class] + torch.normal(mean=0, std = np.sqrt(sigma_noise), size=(hv_d,)).cuda()\n",
    "        \n",
    "    return class_noisy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate data from all clients\n",
    "test_data = []\n",
    "\n",
    "test_labels = []\n",
    "\n",
    "for client in all_dataset:\n",
    "    test_data.append(all_dataset[client]['testdata'])\n",
    "    test_labels.append(all_dataset[client]['testlabels'])\n",
    "\n",
    "test_data = np.concatenate(test_data, axis=0)\n",
    "test_labels = np.concatenate(test_labels, axis=0)\n",
    "\n",
    "\n",
    "# Convert to torch tensors and move to GPU\n",
    "testdata = torch.tensor(test_data, dtype=torch.float64).cuda()\n",
    "testlabels = torch.tensor(test_labels, dtype=torch.long).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP\n",
      "Round 1\n",
      "0.41753533568904594\n",
      "Round 2\n",
      "0.5229681978798587\n",
      "Round 3\n",
      "0.559452296819788\n",
      "Round 4\n",
      "0.6000883392226148\n",
      "Round 5\n",
      "0.6157685512367491\n",
      "Round 6\n",
      "0.6304770318021201\n",
      "Round 7\n",
      "0.6790194346289753\n",
      "Round 8\n",
      "0.678047703180212\n",
      "Round 9\n",
      "0.685821554770318\n",
      "Round 10\n",
      "0.7072879858657244\n"
     ]
    }
   ],
   "source": [
    "print('DP')\n",
    "\n",
    "print(f\"Round {1}\")\n",
    "\n",
    "acc = []\n",
    "\n",
    "class_hvs_list = []\n",
    "for client in all_dataset:\n",
    "    train_data = all_dataset[client]['traindata'][0:batch_size]\n",
    "    train_labels = all_dataset[client]['trainlabels'][0:batch_size]\n",
    "\n",
    "    # Convert to torch tensors and move to GPU\n",
    "    traindata = torch.tensor(train_data, dtype=torch.float64).cuda()\n",
    "    trainlabels = torch.tensor(train_labels, dtype=torch.long).cuda()\n",
    "    \n",
    "\n",
    "    class_hvs = Train_HD(traindata,trainlabels,embed,nClasses,hv_d)    \n",
    "\n",
    "    class_noisy = Noise_first_round(class_hvs,eps,hv_d,batch_size)\n",
    "    \n",
    "    class_hvs_list.append(class_noisy)\n",
    "\n",
    "\n",
    "\n",
    "class_hvs_stack = torch.stack(class_hvs_list,dim=0)\n",
    "\n",
    "class_hvs_mean = torch.mean(class_hvs_stack,dim=0)\n",
    "\n",
    "test_acc = Infer(class_hvs_mean,testdata,testlabels,embed)\n",
    "print(test_acc)\n",
    "acc.append(test_acc)\n",
    "\n",
    "for rnd in range(1,round_needed):\n",
    "    print(f\"Round {rnd+1}\")\n",
    "\n",
    "    \n",
    "    class_hvs_list = []\n",
    "    for client in all_dataset:\n",
    "        train_data = all_dataset[client]['traindata'][rnd*batch_size:(rnd+1)*batch_size]\n",
    "        train_labels = all_dataset[client]['trainlabels'][rnd*batch_size:(rnd+1)*batch_size]\n",
    "\n",
    "        # Convert to torch tensors and move to GPU\n",
    "        traindata = torch.tensor(train_data, dtype=torch.float64).cuda()\n",
    "        trainlabels = torch.tensor(train_labels, dtype=torch.long).cuda()\n",
    "\n",
    "        class_hvs = class_hvs_mean.clone()\n",
    "\n",
    "        class_hvs = Update_HD(class_hvs,traindata,trainlabels,embed,n_epochs)\n",
    "\n",
    "        class_noisy = Pert_Noise(class_hvs,eps,hv_d,batch_size,rnd+1,n_clients)\n",
    "\n",
    "        class_hvs_list.append(class_noisy)\n",
    "    \n",
    "\n",
    "    class_hvs_stack = torch.stack(class_hvs_list,dim=0)\n",
    "    class_hvs_mean = torch.mean(class_hvs_stack,dim=0)\n",
    "\n",
    "    test_acc = Infer(class_hvs_mean,testdata,testlabels,embed)\n",
    "    print(test_acc)\n",
    "    acc.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Class FNR: [0.2449628844114528, 0.23833510074231176, 0.3947298728813559]\n",
      "Per-Class FPR: [0.13500264970853207, 0.2178060413354531, 0.08622746553552492]\n",
      "Macro-Averaged FNR: 0.2927\n",
      "Macro-Averaged FPR: 0.1463\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "for i_sub in list(range(len(testdata))):\n",
    "    encd_sample = torch.sign(torch.tensor(embed(testdata[i_sub]), dtype=torch.float64).cuda())\n",
    "    guess = torch.matmul(class_hvs_mean,encd_sample).argmax()\n",
    "    all_predictions.append(guess.item())\n",
    "    all_labels.append(testlabels[i_sub].item())\n",
    "        \n",
    "cm = confusion_matrix(all_labels, all_predictions, labels=np.unique(np.asarray(all_labels)))\n",
    "\n",
    "fnr_per_class = []\n",
    "fpr_per_class = []\n",
    "\n",
    "for i in range(nClasses):\n",
    "    TP = cm[i, i]  # True Positives for class i\n",
    "    FN = np.sum(cm[i, :]) - TP  # False Negatives for class i\n",
    "    FP = np.sum(cm[:, i]) - TP  # False Positives for class i\n",
    "    TN = np.sum(cm) - (TP + FN + FP)  # True Negatives for class i\n",
    "\n",
    "    # Compute FNR and FPR for class i\n",
    "    FNR = FN / (FN + TP) if (FN + TP) > 0 else 0\n",
    "    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "\n",
    "    fnr_per_class.append(FNR)\n",
    "    fpr_per_class.append(FPR)\n",
    "\n",
    "# Macro-average FNR and FPR\n",
    "macro_fnr = np.mean(fnr_per_class)\n",
    "macro_fpr = np.mean(fpr_per_class)\n",
    "\n",
    "\n",
    "print(\"Per-Class FNR:\", fnr_per_class)\n",
    "print(\"Per-Class FPR:\", fpr_per_class)\n",
    "print(f\"Macro-Averaged FNR: {macro_fnr:.4f}\")\n",
    "print(f\"Macro-Averaged FPR: {macro_fpr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
